{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f653873",
   "metadata": {},
   "source": [
    "# UserProxyAgent \\#\n",
    "#### The UserProxyAgent is a special built-in agent that acts as a proxy for a user to provide feedback to the team.\n",
    "\n",
    "#### To use the UserProxyAgent, you can create an instance of it and include it in the team before running the team. The team will decide when to call the UserProxyAgent to ask for feedback from the user.\n",
    "\n",
    "#### When team calls the UserProxyAgent, it transfers the control to the application/user, and waits for the feedback, once the feedback is provided, the control is transferred back to the team and the team continues its execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5980488b",
   "metadata": {},
   "source": [
    "# NOTE: When UserProxyAgent is called during a run, it blocks the execution of the team until the user provides feedback or errors out. This will hold up the team’s progress and put the team in an unstable state that cannot be saved or resumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf23305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0dd99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agents.\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "assitant = AssistantAgent(\"assistant\", model_client=model_client)\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", input_func=input) # Use input() to get user input from console.\n",
    "\n",
    "#Create the termination condition which will end the conversation when the user says \"APPROVE\".\n",
    "termination = TextMentionTermination(\"APPROVE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96415d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the team\n",
    "team = RoundRobinGroupChat([assitant, user_proxy], termination_condition = termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5464c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a 4-line poem about the ocean.\n",
      "---------- TextMessage (assistant) ----------\n",
      "Waves that dance in deep blue grace,  \n",
      "Whispers of secrets the tides embrace.  \n",
      "Beneath the sun, in endless motion,  \n",
      "The heart of the world, the vast, deep ocean.  \n",
      "TERMINATE\n",
      "---------- TextMessage (user_proxy) ----------\n",
      "APPROVE\n"
     ]
    }
   ],
   "source": [
    "# Run the conversation and stream the console.\n",
    "stream = team.run_stream(task=\"Write a 4-line poem about the ocean.\")\n",
    "\n",
    "await Console(stream)\n",
    "\n",
    "await model_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715b802",
   "metadata": {},
   "source": [
    "# Using Max Turns \\#\n",
    "### This method allows you to pause the team for user input by setting a maximum number of turns. For instance, you can configure the team to stop after the first agent responds by setting max_turns to 1. This is particularly useful in scenarios where continuous user engagement is required, such as in a chatbot.\n",
    "### To implement this, set the max_turns parameter in the RoundRobinGroupChat() constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a576d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "agent_max_turns = AssistantAgent(\"max_turns_agent\", model_client=model_client)\n",
    "\n",
    "# Create the team setting a maximum number of turns to 1.\n",
    "teams = RoundRobinGroupChat([agent_max_turns], max_turns=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a317bdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a 4-line poem about the ocean.\n",
      "---------- TextMessage (max_turns_agent) ----------\n",
      "Waves dance and shimmer under the sun's embrace,  \n",
      "Endless horizon holds nature’s vast grace.  \n",
      "Whispers of the deep tell tales of the tide,  \n",
      "In the ocean's heart, all secrets abide.  \n",
      "TERMINATE\n",
      "---------- TextMessage (max_turns_agent) ----------\n",
      "Waves dance and shimmer under the sun's embrace,  \n",
      "Endless horizon holds nature’s vast grace.  \n",
      "Whispers of the deep tell tales of the tide,  \n",
      "In the ocean's heart, all secrets abide.  \n",
      "TERMINATE\n",
      "---------- TextMessage (max_turns_agent) ----------\n",
      "Waves dance and shimmer under the sun's embrace,  \n",
      "Endless horizon holds nature’s vast grace.  \n",
      "Whispers of the deep tell tales of the tide,  \n",
      "In the ocean's heart, all secrets abide.  \n",
      "TERMINATE\n",
      "---------- TextMessage (user) ----------\n",
      "can you make it little funny\n",
      "---------- TextMessage (max_turns_agent) ----------\n",
      "The ocean's like a giant soup, all salty and blue,  \n",
      "Fish swim in circles, saying, \"What’s wrong with you?\"  \n",
      "Seagulls steal your snacks with a cheeky little squawk,  \n",
      "While we all just wave back, saying, \"Hey! That's my block!\"  \n",
      "TERMINATE\n",
      "---------- TextMessage (max_turns_agent) ----------\n",
      "The ocean's like a giant soup, all salty and blue,  \n",
      "Fish swim in circles, saying, \"What’s wrong with you?\"  \n",
      "Seagulls steal your snacks with a cheeky little squawk,  \n",
      "While we all just wave back, saying, \"Hey! That's my block!\"  \n",
      "TERMINATE\n",
      "---------- TextMessage (max_turns_agent) ----------\n",
      "The ocean's like a giant soup, all salty and blue,  \n",
      "Fish swim in circles, saying, \"What’s wrong with you?\"  \n",
      "Seagulls steal your snacks with a cheeky little squawk,  \n",
      "While we all just wave back, saying, \"Hey! That's my block!\"  \n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "task = \"Write a 4-line poem about the ocean.\"\n",
    "while True:\n",
    "    # Run the conversation and stream the console.\n",
    "    stream = teams.run_stream(task=task)\n",
    "    await Console(stream)\n",
    "    task = input(\"Enter your feedback (type 'exit' to leave):\")\n",
    "    if task.lower().strip() == \"exit\":\n",
    "        break\n",
    "\n",
    "await model_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfee814",
   "metadata": {},
   "source": [
    "# Using Termination Condition \\#\n",
    "###  we focus on HandoffTermination which stops the team when an agent sends a HandoffMessage message.\n",
    "### Let’s create a team with a single AssistantAgent agent with a handoff setting, and run the team with a task that requires additional input from the user because the agent doesn’t have relevant tools to continue processing the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f7297c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.base import Handoff\n",
    "from autogen_agentchat.conditions import TextMentionTermination, HandoffTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5f473e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Create an OpenAI model client.\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "950c8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lazy assistant agent that always hands off to the user.\n",
    "lazy_agent = AssistantAgent(\n",
    "    \"lazy_assistant\",\n",
    "    model_client=model_client,\n",
    "    handoffs=[Handoff(target=\"user\", message=\"Transfer to user.\")],\n",
    "    system_message=\"If you cannot complete the task, transfer to user. Otherwise, when finished, respond with 'TERMINATE'.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63318e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What is the weather in New York?\n",
      "---------- ToolCallRequestEvent (lazy_assistant) ----------\n",
      "[FunctionCall(id='call_MRl0zFAoNnna60wxQTHtLFdo', arguments='{}', name='transfer_to_user')]\n",
      "[Prompt tokens: 167, Completion tokens: 11]\n",
      "---------- ToolCallExecutionEvent (lazy_assistant) ----------\n",
      "[FunctionExecutionResult(content='Transfer to user.', name='transfer_to_user', call_id='call_MRl0zFAoNnna60wxQTHtLFdo', is_error=False)]\n",
      "---------- HandoffMessage (lazy_assistant) ----------\n",
      "Transfer to user.\n",
      "---------- Summary ----------\n",
      "Number of messages: 4\n",
      "Finish reason: Handoff to user from lazy_assistant detected.\n",
      "Total prompt tokens: 167\n",
      "Total completion tokens: 11\n",
      "Duration: 1.11 seconds\n",
      "---------- TextMessage (user) ----------\n",
      "The weather in New York is sunny.\n",
      "---------- TextMessage (lazy_assistant) ----------\n",
      "Thank you for the information! If there's anything else you need, just let me know.\n",
      "---------- ToolCallRequestEvent (lazy_assistant) ----------\n",
      "[FunctionCall(id='call_MLAxrkAO1QwZEACmgXiNdQE4', arguments='{}', name='transfer_to_user')]\n",
      "---------- ToolCallExecutionEvent (lazy_assistant) ----------\n",
      "[FunctionExecutionResult(content='Transfer to user.', name='transfer_to_user', call_id='call_MLAxrkAO1QwZEACmgXiNdQE4', is_error=False)]\n",
      "---------- HandoffMessage (lazy_assistant) ----------\n",
      "Transfer to user.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='0e36f0fd-7a98-4f99-95e6-279b192c3799', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 4, 17, 42, 54, 927497, tzinfo=datetime.timezone.utc), content='The weather in New York is sunny.', type='TextMessage'), TextMessage(id='da9c831e-07ac-48f1-877c-657da62e0bd1', source='lazy_assistant', models_usage=RequestUsage(prompt_tokens=204, completion_tokens=19), metadata={}, created_at=datetime.datetime(2025, 8, 4, 17, 42, 56, 131733, tzinfo=datetime.timezone.utc), content=\"Thank you for the information! If there's anything else you need, just let me know.\", type='TextMessage'), ToolCallRequestEvent(id='59158220-1d90-4a43-b901-bf76ee1fb9d1', source='lazy_assistant', models_usage=RequestUsage(prompt_tokens=226, completion_tokens=11), metadata={}, created_at=datetime.datetime(2025, 8, 4, 17, 42, 56, 986128, tzinfo=datetime.timezone.utc), content=[FunctionCall(id='call_MLAxrkAO1QwZEACmgXiNdQE4', arguments='{}', name='transfer_to_user')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(id='0c6a36f2-9b64-4f74-8763-67faf47375cd', source='lazy_assistant', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 4, 17, 42, 56, 986128, tzinfo=datetime.timezone.utc), content=[FunctionExecutionResult(content='Transfer to user.', name='transfer_to_user', call_id='call_MLAxrkAO1QwZEACmgXiNdQE4', is_error=False)], type='ToolCallExecutionEvent'), HandoffMessage(id='b6e3fa24-da1e-4d14-8a96-7fdcbf35dda8', source='lazy_assistant', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 4, 17, 42, 56, 986128, tzinfo=datetime.timezone.utc), content='Transfer to user.', target='user', context=[], type='HandoffMessage')], stop_reason='Handoff to user from lazy_assistant detected.')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a termination condition that checks for handoff messages.\n",
    "handoff_termination = HandoffTermination(target=\"user\")\n",
    "# Define a termination condition that checks for a specific text mention.\n",
    "text_termination = TextMentionTermination(\"TERMINATE\")\n",
    "\n",
    "# Create a single-agent team with the lazy assistant and both termination conditions.\n",
    "lazy_agent_team = RoundRobinGroupChat([lazy_agent], termination_condition=handoff_termination | text_termination)\n",
    "\n",
    "# Run the team and stream to the console.\n",
    "task = \"What is the weather in New York?\"\n",
    "await Console(lazy_agent_team.run_stream(task=task), output_stats=True)\n",
    "await Console(lazy_agent_team.run_stream(task=\"The weather in New York is sunny.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc293a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "The weather in New York is sunny.\n",
      "---------- TextMessage (lazy_assistant) ----------\n",
      "Thank you for the update! If you need any further information or assistance, feel free to ask.\n",
      "---------- ToolCallRequestEvent (lazy_assistant) ----------\n",
      "[FunctionCall(id='call_Io9wFXSFFqCyZv5aqWbvoT1r', arguments='{}', name='transfer_to_user')]\n",
      "---------- ToolCallExecutionEvent (lazy_assistant) ----------\n",
      "[FunctionExecutionResult(content='Transfer to user.', name='transfer_to_user', call_id='call_Io9wFXSFFqCyZv5aqWbvoT1r', is_error=False)]\n",
      "---------- HandoffMessage (lazy_assistant) ----------\n",
      "Transfer to user.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='05a0db28-771a-4767-b414-a4e2f1a235b3', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 4, 17, 42, 0, 867236, tzinfo=datetime.timezone.utc), content='The weather in New York is sunny.', type='TextMessage'), TextMessage(id='ac5ec133-f1ec-49a0-87d1-05e73de06c87', source='lazy_assistant', models_usage=RequestUsage(prompt_tokens=106, completion_tokens=21), metadata={}, created_at=datetime.datetime(2025, 8, 4, 17, 42, 2, 164695, tzinfo=datetime.timezone.utc), content='Thank you for the update! If you need any further information or assistance, feel free to ask.', type='TextMessage'), ToolCallRequestEvent(id='f9c46b6d-bacb-4677-a395-3fa70ceecf05', source='lazy_assistant', models_usage=RequestUsage(prompt_tokens=130, completion_tokens=11), metadata={}, created_at=datetime.datetime(2025, 8, 4, 17, 42, 3, 490740, tzinfo=datetime.timezone.utc), content=[FunctionCall(id='call_Io9wFXSFFqCyZv5aqWbvoT1r', arguments='{}', name='transfer_to_user')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(id='8657326c-6ba7-4fd6-8039-80cbf1d6661a', source='lazy_assistant', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 4, 17, 42, 3, 490740, tzinfo=datetime.timezone.utc), content=[FunctionExecutionResult(content='Transfer to user.', name='transfer_to_user', call_id='call_Io9wFXSFFqCyZv5aqWbvoT1r', is_error=False)], type='ToolCallExecutionEvent'), HandoffMessage(id='1c9b06f7-b5d5-4d93-9e58-a413231f103a', source='lazy_assistant', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 4, 17, 42, 3, 490740, tzinfo=datetime.timezone.utc), content='Transfer to user.', target='user', context=[], type='HandoffMessage')], stop_reason='Handoff to user from lazy_assistant detected.')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(lazy_agent_team.run_stream(task=\"The weather in New York is sunny.\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen-venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
